# Fractureiser Mitigation Meeting 2023-06-08

Agenda and minutes for the 2023-06-08 meeting on follow-ups and preventions

In the interest of keeping the meeting productive, we are inviting a narrow set of members
from the community, mostly people working on mod repositories, and people who helped
organize the incident response. Please don't feel excluded if you weren't asked to attend.

Please do not comment on this file or any commits touching it on GitHub. You will be
ignored and if you spam we'll delete your comments and block you from the org.

## Where
The meeting is happening on Discord, here: https://discord.gg/zPdFK47682. The meeting will happen in a stage chat, which the general public can *view and listen* but only the attendees listed will be able to speak.

## Time

2023-06-08 9AM PT

## Attendees

Meeting shepherds/drivers:

- Emi (initial responder, organizer)
- Jasmine (organizer)

Meeting secretary/minutes:

- williewillus (incident journalist; Violet Moon)

Members of the Community (Alphabetic):

- cpw (Forge)
- Doctor Oyster (Overwolf Community Team Leader)
- Emma (Modrinth)
- Fury (Overwolf CEO)
- gdude (Quilt)
- Geometrically (Modrinth)
- IMS (CaffeineMC)
- Mikey (FTB)
- modmuss (Fabric)
- Slowpoke (FTB)
- Starchild (Quilt)
- timoreo (Prism Launcher)
- ZekeZ (Prism Launcher)

## Summary of Incident and Response

(this is mostly for the benefit of attendees to get them caught up quickly - this doesn't need to be read aloud or something)

`fractureiser` is a novel self replicating virus that infects Bukkit plugins, Forge Mods, Fabric Mods, and vanilla Minecraft JARs. Infected JARs, upon being loaded, will run as normal, but silently download a series of payloads that steal login tokens, stored browser passwords/payment information, and cryptocurrency. After a computer has been infected, every applicable JAR file on the compromised system will be infected such that if they are shared and run on an another computer, the infection will spread. Compromised Curseforge login tokens were used to gain access to large mod projects and distribute infected JARs to users.

Discussion and responses to the issue began in earnest on June 6th. Samples were gradually discovered, identified, and decompiled. The source of the payloads that propogate the malware and steal passwords/tokens was identified, and swiftly taken down by its host, Serverion. Infected JARs are no longer able to progress or propogate the malware, but infections from prior to the node being taken down may still be active.

At time of writing, samples continue to be reverse engineered in the hopes that, should the attackers attempt to create a new iteration of the malware, its command and control nodes can be taken down as quickly as possible. On June 7th, the attacker attempted to create a new node, which was again swiftly taken down by its host. A web URL pointing to this now-defunct node has been found, and is being actively monitored.

## Agenda

We have about an hour so let's spend 15 minutes on each topic max. I've organized the
topics by my (williewillus') sense of how likely something actionable is to happen. The
less realistic something is the lower down it is. If time constrains us, we may drop those
topics.

### Opaque Review Processes/Security by Obscurity

#### Discussion and Action Items

- What does CurseForge/Modrinth *do* when reviewing a mod?
  - Insert  "what do you do here" meme :)
- What automated checks *are* being run?
  - ?
- What automated checks *should* be put in place?
  - Static analysis?
  - Can we get mod repos to commit to these action plans?
- Semi-OT: Can we get a checksum algorithm that is not MD5 on CF please? MD5 has been
  known broken for years and this made us wary of attempted editing/collision attacks for
  longer than necessary
  - What does Modrinth use?

### Reproducible Builds

One thing that would have helped in the "scanning for tampered mods" part of the response,
was if we knew a specific mod version only had one possible binary output. That is,
reproducible builds given a source checkout. We could have simply rebuilt the mod in
question from source, taken its hash, and compared it to the file under scrutiny to detect
stage 0 infection, rather than going through the complicated exercise of trying to scan
for signatures in the code.

How many of our mods have build scripts plugins or deps with unpinned floating
`-SNAPSHOT` version specifiers in them?

I'm willing to bet all of them, because both
[Fabric](https://github.com/FabricMC/fabric-example-mod/blob/1.20/build.gradle#L2) and
[Forge](https://github.com/MinecraftForge/MinecraftForge/blob/1.19.x/mdk/build.gradle#L4)
have example mods that do just that.

Gradle plugins like Loom and FG traditionally did this so that they could push fixes and
iterate quickly without user action, but it's important now to have auditability.

Supply chain attacks from random modding Mavens being hacked is a very real threat.

#### Discussion and Action Items

- Stop promoting usage of `-SNAPSHOT` in example templates and documentation in favor of
  fixed version numbers
- Update fabric-example-mod and forge MDK example to use Gradle checksum verification and/or locking?
  - https://docs.gradle.org/current/userguide/dependency_verification.html
    - This is the traditional "write hashes into a file and check them" lockfile approach
  - https://docs.gradle.org/current/userguide/dependency_locking.html
    - This is "lock any ranged dependency declarations like `[1, 2)` to one specific
      version until told to update"
- Stand up a working group in Loom/FG to investigate reproducible builds when the gradle
  [flag](https://docs.gradle.org/current/userguide/working_with_files.html#sec:reproducible_archives)
  is set. There may be nondeterminism introduced by parts of the modding toolchain such as
  jar remappers. Each instance needs to be rooted out such that a mod builds reproducibly
  out of the box.
- Crazy idea: F-Droid style, submit source and it gets built by the mod repo?
  - Expensive capacity wise, unlikely to happen.

### Mods Downloading External Files

Mods that download external files which contain executable code are vulnerable to a supply chain attack.

Some existing examples of mods that do this are:
- [Essential](https://modrinth.com/mod/essential)
  - Automatic updater downloads any updates without prompting user. If the Essential
    update servers are compromised, the malicious code will be downloaded upon launching
    minecraft.
- Mods depending on [owolib](https://modrinth.com/mod/owo-lib), such as [gadget](https://modrinth.com/mod/gadget)
  - Will prompt the user to download owo-lib, which will download the jar from
    modrinth. If a malicious jar is added to modrinth with the correct version, it can
    perform a supply chain attack.

Should one of the more popular mods, such as Essential, be compromised, it would allow malware to quickly propagate to millions of users.

#### Discussion and Action Items

- Should mods uploaded to platforms (Modrinth, CurseForge, etc.) be permitted to download
  files containing executable code from external sources?
  - I think no, but how would we enforce this? Start the game with the mod and check it
    doesn't download anything new into the mods folder?

### Code Signing

Binary artifacts released to mod repos should be signed by their author.

Templates and help docs for e.g. Fabric Loom and ForgeGradle should make the UX as easy as
possible to:

- Build releases in CI
- Sign jars in CI at build time
- Upload the signed jars to mod repos in CI

Moving release creation to CI is already more than what many modders do (most people don't
even tag their releases). Keep in mind many modders are amateur programmers that have not
worked in industry and don't know what any of this is.

I can't stress how important it is for this to be as well documented, easy, and
ready-to-use as possible this is, or else no one will use it.

Eventually, mod repos should require signatures for every single upload and reject any
unsigned artifact outright. This will need a rollout period, and still require good
education materials.

#### Discussion and Action Items

- Where should public keys be held and associated with their authors? In other words, what
  prevents a hacker from replacing a public key as well as the signed binary at the same
  time?
  - In the modrinth user account (behind 2fa)?
    - Without organization accounts this can be annoying for mods that can be uploaded by
      multiple people?
    - If Modrinth is compromised a hacker can replace the pubkey and uploade a new signed
      binary at the same time
- PGP signing or java jarsigner stuff?
  - PGP is the standard and used for Maven Central. My impression is no one uses the java
    specific stuff. OpenSSH signing is also an option but is much newer and has no
    established ecosystem. PGP is probably the best choice, unfortunately. We can automate
    away all the crappy parts of it with helpers in Gradle plugins.
- Prior art
  - Forge has had support for signature stuff for years and it's gone unused. What can we
    learn from it?
- Launchers should likely include UI elements to indicate mod signature verification status.
- Immediate followups
  - Modrinth and CurseForge design how public key association/storage will work
  - Mod loaders write extensive documentation about how to:
    1. Create releases in CI using git tags
    2. Automatically sign and upload artifacts from CI


### Sandboxing

Sandboxing the Minecraft process is another defense strategy that can be used to limit the
blast radius of attacks coming from malicious mod code.

In general, it's a hard problem.

Minecraft should only need access to:

- The internet, to authenticate, log into servers, etc.
- Filesystem access to the `.minecraft` instance folder and its recursive descendants

The main thing of interest to lock down here is filesystem access.

On Windows, there does not seem to be any simple to deploy sandboxing system (besides
"play bedrock"). The closest is Chromium's
[model](https://chromium.googlesource.com/chromium/src/+/master/docs/design/sandbox.md)
which would require significant invasive changes to the game.

On macOS, we *could* use Apple's built in sandboxing system known as ["Seatbelt"](https://www.chromium.org/developers/design-documents/sandbox/osx-sandboxing-design/). It is already enforced in apple's app store, but not external apps like Minecraft. However it is still not possible to use it to restrict network access to certain sites.
Below is a image which shows its file permission config which we can use to restrict its access. This could prove to be good enough for what is needed to limit malware and attacks from the code.
![image](media/sandboxfile.png)


On Linux, we have a couple options. First is SELinux/AppArmor. These frameworks are
infamous for being insanely hard to configure and as a result have not been widely
deployed. However, the policies we seek are quite simple, so it's possible this could be
an avenue.

In OpenBSD parlance, all we want to do is [`unveil(2)`](https://man.openbsd.org/unveil) to
all paths in the instance root, but unfortunately this interface isn't available in Linux.

Second, is using a system such as Flatpak.
